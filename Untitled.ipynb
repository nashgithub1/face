{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b275b3b-054f-425b-b579-bcf953680b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb1e902-52dc-468a-b2ef-f5e1069faef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "data_dir = \"/Users/mohamednashath/Desktop/projectface/datadir\"  # Subfolders: naathi, nazeef, riznee, unknown\n",
    "unseen_dir = \"/Users/mohamednashath/Desktop/projectface/unseendir\"  # Unseen data subfolders\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "num_classes = 4\n",
    "epochs = 20\n",
    "k_folds = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255146a9-5681-4e8c-a6a0-4b0098e077b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,  # Reduced for stability\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    validation_split=0.1875  # 15% validation (84 images)\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df56ce44-bf41-4e3f-9894-582a086032e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 456 images belonging to 4 classes.\n",
      "Found 104 images belonging to 4 classes.\n",
      "Found 560 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # 448 images\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # 84 images\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d369cad7-b151-43b5-97d7-c87f1505f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 18:03:29.000596: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-07-26 18:03:29.000693: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-07-26 18:03:29.000700: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-07-26 18:03:29.000738: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-26 18:03:29.000763: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Build MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Initially freeze base\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee719edc-3dc4-41f0-b4ee-0bf9e37f92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fdfdb3-7aca-416c-ac44-f64a8d85498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cnn_env/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 18:03:42.589694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - Precision: 0.2947 - Recall: 0.2029 - accuracy: 0.2932 - loss: 1.9095 - val_Precision: 0.5918 - val_Recall: 0.2788 - val_accuracy: 0.4808 - val_loss: 1.1293\n",
      "Epoch 2/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - Precision: 0.4340 - Recall: 0.3217 - accuracy: 0.3930 - loss: 1.4225 - val_Precision: 0.7059 - val_Recall: 0.3462 - val_accuracy: 0.5962 - val_loss: 0.9726\n",
      "Epoch 3/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - Precision: 0.4792 - Recall: 0.3455 - accuracy: 0.4612 - loss: 1.3616 - val_Precision: 0.8627 - val_Recall: 0.4231 - val_accuracy: 0.7115 - val_loss: 0.7808\n",
      "Epoch 4/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - Precision: 0.6007 - Recall: 0.4695 - accuracy: 0.5477 - loss: 1.1037 - val_Precision: 0.8873 - val_Recall: 0.6058 - val_accuracy: 0.7692 - val_loss: 0.6757\n",
      "Epoch 5/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - Precision: 0.5897 - Recall: 0.4891 - accuracy: 0.5521 - loss: 1.1052 - val_Precision: 0.8933 - val_Recall: 0.6442 - val_accuracy: 0.8462 - val_loss: 0.6387\n",
      "Epoch 6/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - Precision: 0.6993 - Recall: 0.5927 - accuracy: 0.6517 - loss: 0.8621 - val_Precision: 0.8795 - val_Recall: 0.7019 - val_accuracy: 0.7981 - val_loss: 0.5705\n",
      "Epoch 7/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - Precision: 0.7082 - Recall: 0.5756 - accuracy: 0.6535 - loss: 0.8628 - val_Precision: 0.8901 - val_Recall: 0.7788 - val_accuracy: 0.8462 - val_loss: 0.5020\n",
      "Epoch 8/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - Precision: 0.7276 - Recall: 0.6631 - accuracy: 0.6944 - loss: 0.7172 - val_Precision: 0.8989 - val_Recall: 0.7692 - val_accuracy: 0.8942 - val_loss: 0.4555\n",
      "Epoch 9/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - Precision: 0.7263 - Recall: 0.6454 - accuracy: 0.6947 - loss: 0.7915 - val_Precision: 0.9121 - val_Recall: 0.7981 - val_accuracy: 0.8654 - val_loss: 0.4162\n",
      "Epoch 10/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - Precision: 0.7474 - Recall: 0.6667 - accuracy: 0.6997 - loss: 0.6959 - val_Precision: 0.9140 - val_Recall: 0.8173 - val_accuracy: 0.8750 - val_loss: 0.4137\n",
      "Epoch 11/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - Precision: 0.7847 - Recall: 0.7032 - accuracy: 0.7335 - loss: 0.6469 - val_Precision: 0.9381 - val_Recall: 0.8750 - val_accuracy: 0.9038 - val_loss: 0.3547\n",
      "Epoch 12/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - Precision: 0.7965 - Recall: 0.7237 - accuracy: 0.7459 - loss: 0.5972 - val_Precision: 0.9053 - val_Recall: 0.8269 - val_accuracy: 0.8558 - val_loss: 0.3453\n",
      "Epoch 13/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - Precision: 0.7647 - Recall: 0.6922 - accuracy: 0.7281 - loss: 0.5961 - val_Precision: 0.9278 - val_Recall: 0.8654 - val_accuracy: 0.8942 - val_loss: 0.3238\n",
      "Epoch 14/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - Precision: 0.8048 - Recall: 0.7601 - accuracy: 0.7934 - loss: 0.5394 - val_Precision: 0.9192 - val_Recall: 0.8750 - val_accuracy: 0.8942 - val_loss: 0.3108\n",
      "Epoch 15/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - Precision: 0.8401 - Recall: 0.7894 - accuracy: 0.8202 - loss: 0.4481 - val_Precision: 0.9062 - val_Recall: 0.8365 - val_accuracy: 0.8750 - val_loss: 0.3237\n",
      "Epoch 16/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - Precision: 0.8421 - Recall: 0.8045 - accuracy: 0.8290 - loss: 0.4422 - val_Precision: 0.9175 - val_Recall: 0.8558 - val_accuracy: 0.8942 - val_loss: 0.2698\n",
      "Epoch 17/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - Precision: 0.8699 - Recall: 0.8298 - accuracy: 0.8498 - loss: 0.4029 - val_Precision: 0.9394 - val_Recall: 0.8942 - val_accuracy: 0.9327 - val_loss: 0.2580\n",
      "Epoch 18/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - Precision: 0.8600 - Recall: 0.7940 - accuracy: 0.8263 - loss: 0.4242 - val_Precision: 0.9495 - val_Recall: 0.9038 - val_accuracy: 0.9327 - val_loss: 0.2268\n",
      "Epoch 19/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - Precision: 0.8455 - Recall: 0.8118 - accuracy: 0.8234 - loss: 0.4426 - val_Precision: 0.9706 - val_Recall: 0.9519 - val_accuracy: 0.9615 - val_loss: 0.2065\n",
      "Epoch 20/20\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - Precision: 0.8943 - Recall: 0.8331 - accuracy: 0.8585 - loss: 0.3576 - val_Precision: 0.9794 - val_Recall: 0.9135 - val_accuracy: 0.9423 - val_loss: 0.2156\n"
     ]
    }
   ],
   "source": [
    "# Train initial model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da363b1f-2c82-4503-a996-da9a058c37c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 950ms/step - Precision: 0.4969 - Recall: 0.4373 - accuracy: 0.4676 - loss: 1.5701 - val_Precision: 0.9596 - val_Recall: 0.9135 - val_accuracy: 0.9327 - val_loss: 0.2167\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 613ms/step - Precision: 0.6171 - Recall: 0.5361 - accuracy: 0.5832 - loss: 1.1411 - val_Precision: 0.9709 - val_Recall: 0.9615 - val_accuracy: 0.9615 - val_loss: 0.2240\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 428ms/step - Precision: 0.6973 - Recall: 0.6058 - accuracy: 0.6585 - loss: 0.8080 - val_Precision: 0.8980 - val_Recall: 0.8462 - val_accuracy: 0.8558 - val_loss: 0.3062\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 505ms/step - Precision: 0.7961 - Recall: 0.7322 - accuracy: 0.7633 - loss: 0.6122 - val_Precision: 0.9300 - val_Recall: 0.8942 - val_accuracy: 0.9038 - val_loss: 0.2985\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 418ms/step - Precision: 0.8308 - Recall: 0.7453 - accuracy: 0.7956 - loss: 0.4953 - val_Precision: 0.8900 - val_Recall: 0.8558 - val_accuracy: 0.8654 - val_loss: 0.3189\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 501ms/step - Precision: 0.8445 - Recall: 0.8038 - accuracy: 0.8316 - loss: 0.4277 - val_Precision: 0.9109 - val_Recall: 0.8846 - val_accuracy: 0.8942 - val_loss: 0.2839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2f5d0ef50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune: Unfreeze some layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:  # Freeze first 100 layers\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),  # Lower learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Additional fine-tuning epochs\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d26025-4fdc-4e81-bb80-fbbb097a2112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - Precision: 0.9215 - Recall: 0.8813 - accuracy: 0.9187 - loss: 0.2899\n",
      "Test Accuracy: 0.9464, Precision: 0.9539, Recall: 0.9232\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "719f232c-2930-4843-832e-cf2bc32bc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"face_recognition_mobilenet_finetuned.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59a71db3-3344-4125-8761-7b2c969f7d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 4 classes.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step\n",
      "Classification Report for Unseen Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      naathi       0.50      0.40      0.44         5\n",
      "      nazeef       0.67      1.00      0.80         2\n",
      "      riznee       0.38      0.75      0.50         4\n",
      "     unknown       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.55      0.61      0.54        18\n",
      "weighted avg       0.56      0.50      0.48        18\n",
      "\n",
      "Confusion Matrix for Unseen Data:\n",
      "[[2 0 2 1]\n",
      " [0 2 0 0]\n",
      " [1 0 3 0]\n",
      " [1 1 3 2]]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model(\"face_recognition_mobilenet_finetuned.h5\")\n",
    "\n",
    "# Evaluate on unseen dataset\n",
    "unseen_datagen = ImageDataGenerator(rescale=1./255)\n",
    "unseen_generator = unseen_datagen.flow_from_directory(\n",
    "    unseen_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get predictions and true labels\n",
    "unseen_predictions = model.predict(unseen_generator)\n",
    "unseen_pred_classes = np.argmax(unseen_predictions, axis=1)\n",
    "unseen_true_classes = unseen_generator.classes\n",
    "class_names = list(unseen_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report for Unseen Data:\")\n",
    "print(classification_report(unseen_true_classes, unseen_pred_classes, target_names=class_names))\n",
    "print(\"Confusion Matrix for Unseen Data:\")\n",
    "print(confusion_matrix(unseen_true_classes, unseen_pred_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a13d65af-fb9b-4a35-a016-79a2a437b52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Prediction Probabilities: [0.16942346 0.00610451 0.8104078  0.01406431]\n",
      "Predicted: riznee with probability 0.8104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.16942346, 0.00610451, 0.8104078 , 0.01406431], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/himas.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5929f7f6-077a-4018-b8c8-1d2a49a67bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Prediction Probabilities: [0.28355327 0.07862822 0.46170962 0.17610887]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.28355327, 0.07862822, 0.46170962, 0.17610887], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/riznee.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c4901a2-c32b-4d5e-9f61-b5519159e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Prediction Probabilities: [0.03310942 0.00816704 0.9576935  0.00103004]\n",
      "Predicted: riznee with probability 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.03310942, 0.00816704, 0.9576935 , 0.00103004], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/riznee2.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f99fafd-7abe-431a-97ee-6ac483545896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
      "Prediction Probabilities: [0.21405499 0.04303099 0.21569525 0.5272188 ]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.21405499, 0.04303099, 0.21569525, 0.5272188 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/zaidh.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7330d40b-d14e-46e9-a044-773bca08da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Prediction Probabilities: [0.00306398 0.01258434 0.03061086 0.9537409 ]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00306398, 0.01258434, 0.03061086, 0.9537409 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/sulaim.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "771b9aaf-3509-4fbd-8fff-07e2738fb458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Prediction Probabilities: [0.86136585 0.01629046 0.09637257 0.02597111]\n",
      "Predicted: naathi with probability 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86136585, 0.01629046, 0.09637257, 0.02597111], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/mirfak.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bda7b247-f844-4426-8dc1-613185ed23b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Prediction Probabilities: [0.06766798 0.20509942 0.11383631 0.6133963 ]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.06766798, 0.20509942, 0.11383631, 0.6133963 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/naathi.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d844027-2e96-4940-945d-2bd1027018dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Prediction Probabilities: [0.38997442 0.00372637 0.57600665 0.03029254]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.38997442, 0.00372637, 0.57600665, 0.03029254], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/naathi2.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec3c609-f678-4338-b78e-4120ad2e4470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Prediction Probabilities: [0.6549201  0.1857676  0.07178534 0.08752697]\n",
      "Predicted: naathi with probability 0.6549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6549201 , 0.1857676 , 0.07178534, 0.08752697], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/naathi3.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faaf54b9-bab4-4199-8274-283c4a6abe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Prediction Probabilities: [4.1832533e-01 1.5424842e-02 5.6611836e-01 1.3149495e-04]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.1832533e-01, 1.5424842e-02, 5.6611836e-01, 1.3149495e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/naathi4.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b877573f-79ce-4c4b-877f-62b498a8eeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Prediction Probabilities: [0.26608196 0.01811185 0.7050111  0.01079501]\n",
      "Predicted: riznee with probability 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.26608196, 0.01811185, 0.7050111 , 0.01079501], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/naathi5.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c5edbba-9c84-472d-9a16-eb89695c17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Prediction Probabilities: [4.5205924e-01 4.5334743e-04 5.4710495e-01 3.8248004e-04]\n",
      "Not matching any known person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.5205924e-01, 4.5334743e-04, 5.4710495e-01, 3.8248004e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image with adjustable threshold\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path, model, threshold=0.6):  # Adjusted threshold\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0]\n",
    "    max_prob = np.max(prediction)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    class_names = ['naathi', 'nazeef', 'riznee', 'unknown']\n",
    "    \n",
    "    print(f\"Prediction Probabilities: {prediction}\")\n",
    "    if max_prob > threshold and class_idx != 3:\n",
    "        print(f\"Predicted: {class_names[class_idx]} with probability {max_prob:.4f}\")\n",
    "    else:\n",
    "        print(\"Not matching any known person\")\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "predict_image(\"/Users/mohamednashath/Desktop/projectface/testrandom/naathi6.jpeg\", model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08f3ef-f382-41e4-b1d8-0fdddbf1f43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
